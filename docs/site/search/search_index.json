{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MBD Assignment Documentation This Documentation consists of the answers to the assignment questions and the code used to solve the assignment. You can find the readme file in the particular exercise folders for more information. Private Repository till grades are released Due to academic integrity policies, The source code will be submitted in the group's tab. And all the information about the code & application can be found in the documentation and report submitted. Exercise 3 Run the given program in both standalone and pseudo-distributed mode and record the outputs. The program should be able to run in both modes and the outputs should be the same. You can find the code in the exercise3 folder under both MacOS & Cloudera folders. The instructions to run the program is given here How to run the program. For MacOS, you can find the installation guide here For Windows, you can find the installation guide here Folder Structure The repository consists of two different OS folders as both of team members used different setup for running the assignment problems, For Mac OS with M1 Chip we have used Docker and VM Cloudera was done by the Assignment Handout instructions. Exercise 3 & 4 and the report latex file will found on the root. mbd - assignment \u251c\u2500\u2500 README . md \u251c\u2500\u2500 package . json \u251c\u2500\u2500 . gitignore \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 docs \u2502 \u2514\u2500\u2500 mkdocs . yml \u251c\u2500\u2500 MacOS \u2502 \u251c\u2500\u2500 Exercise4 \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 com . mbdassign . wordfreq \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomUniqueWordCount . java # Custom Unique Word Count Using Chain Mapper \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomWordCount . java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 UniqueWordsTwoJobs . java # Custom Unique Words Using Two MapReduceJobs \u2502 \u2502 \u251c\u2500\u2500 input # input folders \u2502 \u2502 \u251c\u2500\u2500 output # output folders ( Artifacts ) \u2502 \u251c\u2500\u2500 Exercise3 \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 com . basicsetup . hadoop \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 WordCount . java \u2502 \u2502 \u251c\u2500\u2500 input # input folders \u2502 \u2502 \u251c\u2500\u2500 output # output folders ( Artifacts ) \u251c\u2500\u2500 VM Cloudera \u2502 \u251c\u2500\u2500 Exercise 4 \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 com . mbdassign . wordfreq \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomUniqueWordCount . java # Custom Unique Word Count Using Chain Mapper \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomWordCount . java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 UniqueWordsTwoJobs . java # Custom Unique Words Using Two MapReduceJobs \u2514\u2500\u2500 src Cloudera Setup Instructions MacOS Instructions Requirement The best way to install Docker on MacOS is Homebrew Cask. brew cask install docker # Install Docker open /Applications/Docker.app # Start Docker Using docker-hadoop To run Hadoop on Arm64 (Apple M1 Chip) and Intel Native we have used docker-hadoop Spinning up the environment for Standalone mode Open terminal and clone the docker-hadoop. Then run the following commands git clone https://github.com/wxw-matt/docker-hadoop # Clone the docker-hadoop cd hadoop-standalone # Go to the docker-hadoop folder docker build -t wxwmatt/hadoop-standalone:2.1.1-hadoop3.3.1-java8 . # Build the image Running the Hadoop Standalone mode Once the image is built, you can get in the container by running the following command docker container run --name standalone -it { $imageID } /bin/bash # Run the container To get the imageID You can use the command docker images to get the imageID. The commands given below will run the Hadoop Standalone mode. mkdir -p /hadoop/input/ # Create the input folder cp input/* /hadoop/input/ # Copy the input files to the input folder hadoop jar { $jarFileName } .jar { $className } /hadoop/input/ /hadoop/output/ # Run the jar file cat /hadoop/output/part-r-00000 # Print the output Spinning up the environment for Pseudo-distributed mode Open terminal and clone the docker-hadoop. Then run the following commands git clone https://github.com/wxw-matt/docker-hadoop # Clone the docker-hadoop cd docker-hadoop # Go to the docker-hadoop folder docker-compose up # Spin up the environment and wait for the environment to spin up. Running the Hadoop Job (Pseduo Distributed Mode) Once the environment is up and running, we can run the Hadoop Job. We can do the following inside the namenode container of the environment. The namenode container will be mounting the /app folder of the environment from the host machine. The /app folder will contain the jars and the input files for the program. docker exec -it namenode /bin/bash hdfs dfs -mkdir /input hdfs dfs -put /app/input/* /input hdfs dfs -ls /input hdfs dfs -cat /input/input.txt hadoop jar /app/WordCount.jar com.basicsetup.hadoop.WordCount /input/input.txt /output hdfs dfs -ls /output hdfs dfs -cat /output/part-r-00000 hdfs dfs -get /output exit The output of the program will be stored in the /output folder in the container, to get the output from the container, we can use the following command. docker cp namenode:/app/output . Your local machine will have the /output folder with the output of the program. Special Thanks for Matt \u2764\ufe0f for the work on Docker Hadoop .","title":"Home"},{"location":"#welcome-to-mbd-assignment-documentation","text":"This Documentation consists of the answers to the assignment questions and the code used to solve the assignment. You can find the readme file in the particular exercise folders for more information. Private Repository till grades are released Due to academic integrity policies, The source code will be submitted in the group's tab. And all the information about the code & application can be found in the documentation and report submitted.","title":"Welcome to MBD Assignment Documentation"},{"location":"#exercise-3","text":"Run the given program in both standalone and pseudo-distributed mode and record the outputs. The program should be able to run in both modes and the outputs should be the same. You can find the code in the exercise3 folder under both MacOS & Cloudera folders. The instructions to run the program is given here","title":"Exercise 3"},{"location":"#how-to-run-the-program","text":"For MacOS, you can find the installation guide here For Windows, you can find the installation guide here","title":"How to run the program."},{"location":"#folder-structure","text":"The repository consists of two different OS folders as both of team members used different setup for running the assignment problems, For Mac OS with M1 Chip we have used Docker and VM Cloudera was done by the Assignment Handout instructions. Exercise 3 & 4 and the report latex file will found on the root. mbd - assignment \u251c\u2500\u2500 README . md \u251c\u2500\u2500 package . json \u251c\u2500\u2500 . gitignore \u251c\u2500\u2500 docs \u2502 \u251c\u2500\u2500 docs \u2502 \u2514\u2500\u2500 mkdocs . yml \u251c\u2500\u2500 MacOS \u2502 \u251c\u2500\u2500 Exercise4 \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 com . mbdassign . wordfreq \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomUniqueWordCount . java # Custom Unique Word Count Using Chain Mapper \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomWordCount . java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 UniqueWordsTwoJobs . java # Custom Unique Words Using Two MapReduceJobs \u2502 \u2502 \u251c\u2500\u2500 input # input folders \u2502 \u2502 \u251c\u2500\u2500 output # output folders ( Artifacts ) \u2502 \u251c\u2500\u2500 Exercise3 \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 com . basicsetup . hadoop \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 WordCount . java \u2502 \u2502 \u251c\u2500\u2500 input # input folders \u2502 \u2502 \u251c\u2500\u2500 output # output folders ( Artifacts ) \u251c\u2500\u2500 VM Cloudera \u2502 \u251c\u2500\u2500 Exercise 4 \u2502 \u2502 \u251c\u2500\u2500 src \u2502 \u2502 \u2502 \u251c\u2500\u2500 com . mbdassign . wordfreq \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomUniqueWordCount . java # Custom Unique Word Count Using Chain Mapper \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 CustomWordCount . java \u2502 \u2502 \u2502 \u2502 \u251c\u2500\u2500 UniqueWordsTwoJobs . java # Custom Unique Words Using Two MapReduceJobs \u2514\u2500\u2500 src","title":"Folder Structure"},{"location":"#cloudera-setup-instructions","text":"","title":"Cloudera Setup Instructions"},{"location":"#macos-instructions","text":"","title":"MacOS Instructions"},{"location":"#requirement","text":"The best way to install Docker on MacOS is Homebrew Cask. brew cask install docker # Install Docker open /Applications/Docker.app # Start Docker","title":"Requirement"},{"location":"#using-docker-hadoop","text":"To run Hadoop on Arm64 (Apple M1 Chip) and Intel Native we have used docker-hadoop","title":"Using docker-hadoop"},{"location":"#spinning-up-the-environment-for-standalone-mode","text":"Open terminal and clone the docker-hadoop. Then run the following commands git clone https://github.com/wxw-matt/docker-hadoop # Clone the docker-hadoop cd hadoop-standalone # Go to the docker-hadoop folder docker build -t wxwmatt/hadoop-standalone:2.1.1-hadoop3.3.1-java8 . # Build the image","title":"Spinning up the environment for Standalone mode"},{"location":"#running-the-hadoop-standalone-mode","text":"Once the image is built, you can get in the container by running the following command docker container run --name standalone -it { $imageID } /bin/bash # Run the container To get the imageID You can use the command docker images to get the imageID. The commands given below will run the Hadoop Standalone mode. mkdir -p /hadoop/input/ # Create the input folder cp input/* /hadoop/input/ # Copy the input files to the input folder hadoop jar { $jarFileName } .jar { $className } /hadoop/input/ /hadoop/output/ # Run the jar file cat /hadoop/output/part-r-00000 # Print the output","title":"Running the Hadoop Standalone mode"},{"location":"#spinning-up-the-environment-for-pseudo-distributed-mode","text":"Open terminal and clone the docker-hadoop. Then run the following commands git clone https://github.com/wxw-matt/docker-hadoop # Clone the docker-hadoop cd docker-hadoop # Go to the docker-hadoop folder docker-compose up # Spin up the environment and wait for the environment to spin up.","title":"Spinning up the environment for Pseudo-distributed mode"},{"location":"#running-the-hadoop-job-pseduo-distributed-mode","text":"Once the environment is up and running, we can run the Hadoop Job. We can do the following inside the namenode container of the environment. The namenode container will be mounting the /app folder of the environment from the host machine. The /app folder will contain the jars and the input files for the program. docker exec -it namenode /bin/bash hdfs dfs -mkdir /input hdfs dfs -put /app/input/* /input hdfs dfs -ls /input hdfs dfs -cat /input/input.txt hadoop jar /app/WordCount.jar com.basicsetup.hadoop.WordCount /input/input.txt /output hdfs dfs -ls /output hdfs dfs -cat /output/part-r-00000 hdfs dfs -get /output exit The output of the program will be stored in the /output folder in the container, to get the output from the container, we can use the following command. docker cp namenode:/app/output . Your local machine will have the /output folder with the output of the program. Special Thanks for Matt \u2764\ufe0f for the work on Docker Hadoop .","title":"Running the Hadoop Job (Pseduo Distributed Mode)"}]}